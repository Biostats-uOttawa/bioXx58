{
  "hash": "c8dee10489592c99a7e4942ba1a513cb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Linear models and generalized linear models\"\nsubtitle: \"in R\"\nauthor: \"Julien Martin\"\ninstitute: BIO 8940 - Lecture 4\ndate: today\nformat:\n  revealjs: \n    width: 1600\n    height: 950\n    chalkboard: true\n    theme: [default]\n    css: assets/theme_chalk/whiteboard-blue.css\n#    logo: assets/MAD_logo_small_rb.png\n    footer: BIO 8940 - Lecture 4\n    show-notes: false\n    output-ext: \"slides.html\"\n  html:\n    self-contained: true\n    number-sections: true\n    code-link: true\n    format-links: false\n    css: assets/css/notes.css\n    number-depth: 2\n    comments:\n      hypothesis: true\n    output-ext: notes.html\neditor:\n  render-on-save: true\nengine: knitr\n---\n\n\n\n# Linear models\n\n\n\n\n\n\n\n\n\n\n## What is a linear regression\n\n### Simple linear regression\n\n$$\nY_i = \\beta_0 + \\beta_1 x_i + \\epsilon \\\\\n\\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n$$\n\nor in distributional notation $Y \\sim N(\\beta_0 + \\beta_1 x, \\sigma^2_{\\epsilon})$\n \n\n### General linear model\n\n$$\nY_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_1 x_{2i} + ... + \\epsilon \\\\\n\\epsilon \\sim N(0, \\sigma^2_{\\epsilon})\n$$\n\nand $Y \\sim N(\\beta_0 + \\beta_1 x_{1i} + \\beta_1 x_{2i} + ..., \\sigma^2)$\n\n## Linear model assumptions\n\nSome are made on the residuals and others on the independent variables.\nNone are made on the (unconditionned) dependent variable. \n\nResiduals are assumed to:\n\n\n* have a mean of zero\n* be independent\n* be normally distributed\n* be homoscedastic\n\n\nIndependent variables are assumed to:\n\n- have a linear relation with Y\n- be measured without error\n- to be independent from each other\n\n\n\n## Maximum likelihood\n\nTechnique used for estimating the parameters of a given distribution, using some observed data\n\n\\\n\n[For Example:]{.underline}\n\n\\\n\nPopulation is known to follow a “normal distribution” but “mean” and “variance” are unknown, MLE can be used to estimate them using a limited sample of the population.\n\n\n\n## Likelihood vs probability\n\nWe maximize the likelihood and make inferences on the probability\n\n\n### Likelihood\n\n$$\nL(parameters | data)\n$$\n\nHow likely it is to get those parameters given the data.\n\n\n\n### Probability\n\n$$\nP(data | null\\ parameters)\n$$\n\nProbability to get the data given the null parameters. Or how probable it is to get those data according to the null model.\n\n\n\n## Maximum likelihood approach\n\n$$\nL(parameters | data) = \\prod_{i=1}^{n} f(data_i | parameters)\n$$\n\nwhere f is the probability density function of your model.\n\n\nWorking with product is more painful than with sum, we can take the log:\n\n$$\nln(L(parameters | data)) = \\sum_{i=1}^{n} ln(f(data_i | parameters))\n$$\n\n\nNeed to solve:\n\n$$\n\\frac{\\delta ln(L(parameters | data)}{\\delta parameters} = 0\n$$\n\nFor multiple regression, the parameters $\\beta$s are given by $\\beta = (X^T X)^{-1} X^T y$\n\n\n## Doing linear models in R\n\n\nSimply use `lm()` function.\nIt works for everything anova, ancova, t-test.\n\n\nWe will use data of sturgeon measurements at different locations in Canada.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat <- read.csv(\"data/lm_example.csv\")\nstr(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t92 obs. of  4 variables:\n $ year   : int  1978 1978 1978 1978 1978 1978 1978 1978 1978 1978 ...\n $ fklngth: num  41.9 50.2 50.2 47.3 49.6 ...\n $ locate : chr  \"NELSON      \" \"LOFW        \" \"LOFW        \" \"NELSON      \" ...\n $ age    : int  11 24 23 20 23 20 23 19 17 14 ...\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Fitting a model and checking assumptions\n\nFirst we load the needed packages for:\n\n* data manipulation: `tidyverse`\n* fancy plots: `ggplot2`\n* type III anova: `car`\n* fancy and nicer visual assumptions checks: `performance`\n* formal assumptions tests: `lmtest`\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"4\"}\nlibrary(car)\nlibrary(performance)\nlibrary(lmtest)\nlibrary(tidyverse)\n```\n:::\n\n\n\n\n\n\n## Data exploration\n\n::: {.panel-tabset}\n\n## R Code\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = dat, aes(x = age, y = fklngth)) +\n  facet_grid(. ~ locate) +\n  geom_point() +\n  stat_smooth(method = lm, se = FALSE) +\n  stat_smooth(se = FALSE, color = \"red\") +\n  labs(\n    y = \"Fork length\",\n    x = \"Age\"\n  )\n```\n:::\n\n\n\n\n\n## Plot\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/plot1-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n:::\n\n\n## Creating log10 transform\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat <- dat %>%\n  mutate(\n    lage = log10(age),\n    lfkl = log10(fklngth)\n  )\n```\n:::\n\n\n\n\n\n\n## Data exploration: with log\n\n::: {.panel-tabset}\n\n## Code\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(data = dat, aes(x = lage, y = lfkl)) +\n  facet_grid(. ~ locate) +\n  geom_point() +\n  stat_smooth(method = lm, se = FALSE) +\n  stat_smooth(se = FALSE, color = \"red\") +\n  labs(\n    y = \"log 10 Fork length\",\n    x = \"Log 10 Age\"\n  )\n```\n:::\n\n\n\n\n## Plot\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/l10-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n:::\n\n\n\n\n## Fit the model\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1 <- lm(lfkl ~ lage + locate + lage:locate, data = dat)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = lfkl ~ lage + locate + lage:locate, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.09375 -0.01864 -0.00253  0.02090  0.08030 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              1.24287    0.04370  28.443  < 2e-16 ***\nlage                     0.31431    0.03292   9.546 3.08e-15 ***\nlocateNELSON             0.19295    0.06331   3.048  0.00304 ** \nlage:locateNELSON       -0.14276    0.04902  -2.912  0.00455 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02823 on 88 degrees of freedom\nMultiple R-squared:  0.5664,\tAdjusted R-squared:  0.5516 \nF-statistic: 38.31 on 3 and 88 DF,  p-value: 6.197e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Anova for factors\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nAnova(m1, type = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnova Table (Type III tests)\n\nResponse: lfkl\n             Sum Sq Df  F value    Pr(>F)    \n(Intercept) 0.64467  1 809.0107 < 2.2e-16 ***\nlage        0.07262  1  91.1310 3.079e-15 ***\nlocate      0.00740  1   9.2901  0.003042 ** \nlage:locate 0.00676  1   8.4815  0.004546 ** \nResiduals   0.07012 88                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Assumptions (classic)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2))\nplot(m1)\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n## Assumptions (Nicer)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheck_model(m1)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n## Formal tests\n\n### Normality of residuals\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nshapiro.test(residuals(m1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  residuals(m1)\nW = 0.97639, p-value = 0.09329\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Formal tests\n\n### Heteroscedasticity\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbptest(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  m1\nBP = 1.8366, df = 3, p-value = 0.607\n```\n\n\n:::\n:::\n\n\n\n\n\n## Formal tests\n\n### Linearity\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresettest(m1, power = 2:3, type = \"fitted\", data = dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tRESET test\n\ndata:  m1\nRESET = 1.6953, df1 = 2, df2 = 86, p-value = 0.1896\n```\n\n\n:::\n:::\n\n\n\n\n\n# Generalized linear models\n\n\n\n## Generalized linear models\n\nAn extension to **linear models**\n\nGLM expresses the transformed conditional expectation of the dependent variable `Y` as a linear combination of the regression variables `X`\n\nModel has 3 components\n\n- a dependent variable Y with a response distribution to model it: **Gaussian**, **Binomial**, **Bernouilli**, **Poisson**, **negative binomial**, **zero-inflated ...**, **zero-truncated ...**, ...\n\n\n- linear predictors (or independent variables)\n$$\n\\eta = \\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k\n$$\n\n\n- a link function such that\n$$\nE(Y |X) = \\mu = g^{-1} (\\eta)\n$$\n\n<!-- - a structural component or additive expression \n- a link function: $g(\\mu)$ -->\n\n\n\n## Dependent variable\n\n* when continuous and follows *conditional* normal distribution, called **Linear regression**\n\n* Binary outcomes (success/failure), follows a *Binomial distribution*, called **Logistic regression** \n\n* Count data (number of events), follows a *Poisson*, called **Poisson regression**\n\n\n\n## Classic link functions\n\n* Identity link (form used in linear regression models)\n\n$$\ng(\\eta) = \\mu\n$$\n\n\n* Log link (used when $\\mu$ cannot be negative, *e.g.* Poisson data)\n\n$$\ng(\\eta) = log(\\mu)\n$$ \n\n\nLogit link (used when \\mu is bounded between 0 and 1, *e.g.* binary data)\n\n$$\ng(\\eta) = log\\left(\\frac{\\mu}{1-\\mu}\\right)\n$$\n\n\n## Linear regression\n\n* Y: continuous\n\n* Response distribution: Gaussian\n\n* Link function: identity\n\n$$\ng(\\eta) = \\mu \\\\\n\\mu(X_1, ...,X_k) = \\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k\n$$\n\n\n\n## Logistic regression\n\n* Y: binary or proportion\n\n* Response distribution: Binomial or bernoulli\n\n* Link function: logit\n\n$$\ng(\\eta) = ln\\left(\\frac{\\mu}{1-\\mu}\\right) \\\\\n\\mu(X_1, ...,X_k) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k)}}\n$$\n\n\n\n## Poisson regression\n\n* Y: discrete variable (integers)\n\n* Response distribution: Poisson or Negative binomial\n\n* Link function: natural logarithm\n\n$$\ng(\\eta) = ln(\\mu) \\\\\n\\mu(X_1, ...,X_k) = e^{\\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k}\n$$\n\n\n\n## Model assumptions\n\n\n- Easy answer none or really few\n\n- More advanced answer I am not sure, it is complicated\n\n- Just check residuals I as usual\n\n- Technically only 3 assumption:\n    - **Variance is a function of the mean specific to the distribution used**\n\n    - observations are independent\n\n    - linear relation on the latent scale\n\n### GLMs do not care if the residual errors are Gaussian as long as the specified mean-variance relationship is satisfied by the data\n\n\n* what about DHaRMA ? It's complicated\n\n\n## Choosing a link function\n\nA link function should map the stuctural component from $(-\\infty,\\infty)$ to the distribution interval (*e.g.* (0,1) for binomial)\n\nSo number of link function possible is extremley large.\n\n\n### Choice of **link** function heavily influenced by field tradiditon\n\n\nFor binomial models\n\n- **logit** assume modelling probability of an observation to be one\n- **probit** assume binary outcome from a hidden gaussian variable (*i.e.* threshold model)\n- **logit** & **probit** are really similar, both are symmetric but **probit** tapers faster. **logit** coefficient easier to interpret directly\n- **cologlog** not-symmetrical\n\n\n# Logistic regression\n\n\n## Data\n\nHere is some data to play with from a study on bighorn sheep.\n\nWe will look at the relation between reproduction and age\n\nLoading and tweaking the data\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmouflon0 <- read.csv(\"data/mouflon.csv\")\nmouflon <- mouflon0 %>%\n  arrange(age) %>%\n  mutate(\n    reproduction = case_when(\n      age >= 13 ~ 0,\n      age <= 4 ~ 1,\n      .default = reproduction\n    )\n  )\n```\n:::\n\n\n\n\n## First plot\n\n::: {.panel-tabset}\n## Code\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbubble <- data.frame(\n  age = rep(2:16, 2),\n  reproduction = rep(0:1, each = 15),\n  size = c(table(mouflon$age, mouflon$reproduction))\n) %>%\n  mutate(size = ifelse(size == 0, NA, size))\nggplot(\n  bubble,\n  aes(x = age, y = reproduction, size = size)\n) +\n  geom_point(alpha = 0.8) +\n  scale_size(range = c(.1, 20), name = \"Nb individuals\")\n```\n:::\n\n\n\n\n## Plot\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/f_plot-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n:::\n\n\n## Fitting the logistic regression\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1 <- glm(reproduction ~ age, data = mouflon,   family = binomial)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = reproduction ~ age, family = binomial, data = mouflon)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  3.19921    0.25417   12.59   <2e-16 ***\nage         -0.36685    0.03287  -11.16   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 928.86  on 715  degrees of freedom\nResidual deviance: 767.51  on 714  degrees of freedom\n  (4 observations deleted due to missingness)\nAIC: 771.51\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n\n## Checking assumptions\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimulationOutput <- simulateResiduals(m1)\nplot(simulationOutput)\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-21-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n## Plotting predictions (latent scale)\n\nplotting the model prediction on the link (latent) scale\n\n\n\n::: {.cell layout-align=\"center\" output-location='slide'}\n\n```{.r .cell-code}\nmouflon$logit_ypred <- 3.19921 - 0.36685 * mouflon$age\nplot(logit_ypred ~ jitter(age), mouflon)\npoints(mouflon$age, mouflon$logit_ypred, col = \"red\", type = \"l\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-22-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n## Plotting predictions (obs scale)\n\nplotting on the observed scale\n\n\n\n\n::: {.cell layout-align=\"center\" output-location='slide'}\n\n```{.r .cell-code}\nmouflon$ypred <- exp(mouflon$logit_ypred) / (1 + exp(mouflon$logit_ypred))\nggplot(mouflon, aes(x = age, y = reproduction)) +\n  geom_jitter(height = 0.01) +\n  geom_line(aes(y=ypred), color = \"red\")\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-23-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n\n## Plotting predictions (obs scale)\n\n::: {.panel-tabset}\n## Code\n\nbut it can be much simpler\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat_predict <- data.frame(\n  age = seq(min(mouflon$age), max(mouflon$age), length = 100)\n) %>%\n  mutate(\n    reproduction = predict(m1, type = \"response\", newdata = .)\n  )\n\nggplot(mouflon, aes(x = age, y = reproduction)) +\n  geom_jitter(height = 0.01) +\n  geom_line(data = dat_predict, aes(x = age, y = reproduction), color = \"red\")\n```\n:::\n\n\n\n\n## Plot\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/pred_glm-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n:::\n\n\n## Your turn\n\nwe can do the same things with more complex models\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2 <- glm(\n  reproduction ~ age + mass_sept + as.factor(sex_lamb) +\n    mass_gain + density + temp,\n  data = mouflon,\n  family = binomial\n)\n```\n:::\n\n\n\n\n\n## check model\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheck_model(m2)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-29-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n## with DHaRMA\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsimulationOutput <- simulateResiduals(m2)\nplot(simulationOutput)\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-30-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n# Poisson regression\n\n## Data\n\ndata on galapagos islands species richness\n\nFit 3 models:\n\n- model of total number of species\n- model of proportion of endemics to total\n- model of species density\n\n---\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngala <- read.csv(\"data/gala.csv\")\nplot(Species ~ Area, gala)\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-31-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n---\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(Species ~ log(Area), gala)\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-32-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n---\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhist(gala$Species)\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-33-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n---\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodpl <- glm(Species ~ Area + Elevation + Nearest, family = poisson, gala)\nsummary(modpl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = Species ~ Area + Elevation + Nearest, family = poisson, \n    data = gala)\n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  3.548e+00  3.933e-02  90.211  < 2e-16 ***\nArea        -5.529e-05  1.890e-05  -2.925  0.00344 ** \nElevation    1.588e-03  5.040e-05  31.502  < 2e-16 ***\nNearest      5.921e-03  1.466e-03   4.039 5.38e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3510.7  on 29  degrees of freedom\nResidual deviance: 1797.8  on 26  degrees of freedom\nAIC: 1966.7\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n\n\n---\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nres <- simulateResiduals(modpl)\ntestDispersion(res)\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-35-1.png){fig-align='center' width=3600}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 110.32, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n\n\n---\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nc(mean(gala$Species), var(gala$Species))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]    85.23333 13140.73678\n```\n\n\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1, 2))\nhist(gala$Species)\nhist(rpois(nrow(gala), mean(gala$Species)))\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-36-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n---\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntestZeroInflation(res)\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-37-1.png){fig-align='center' width=3600}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa zero-inflation test via comparison to expected zeros with\n\tsimulation under H0 = fitted model\n\ndata:  simulationOutput\nratioObsSim = NaN, p-value = 1\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n\n\n---\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npar(mfrow = c(2, 2))\nplot(modpl)\n```\n\n::: {.cell-output-display}\n![](lec-04_lm_glm_files/figure-revealjs/unnamed-chunk-38-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n\n# Happy coding\n\n![](assets/img_l4/unicorn.png){fig-align=\"center\"}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}